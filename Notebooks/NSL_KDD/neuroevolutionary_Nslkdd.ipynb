{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bqRsX6C_7Pjt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(5)\n",
    "\n",
    "\n",
    "#Prevent Tensorflow messages from showing up\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7358/3356459622.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Neural network with properties specified\n",
    "def makeDNN(numOfLayers, numOfNeurons, activationFunc):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_dim=122))\n",
    "    model.add(tf.keras.layers.Dense(numOfNeurons, activation = activationFunc))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    for i in range(numOfLayers):\n",
    "        model.add(tf.keras.layers.Dense(numOfNeurons, activation = activationFunc,kernel_regularizer='l2')) # Regularization added\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(5, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = [keras.metrics.SparseCategoricalAccuracy()])\n",
    "    return model\n",
    "\n",
    "class NeuralNet:\n",
    "    def __init__(self, layers, nodes, activation):\n",
    "        self.layers = layers\n",
    "        self.nodes = nodes\n",
    "        self._testAccuracy = 0\n",
    "        self._testLoss = 1\n",
    "        self.activation = activation\n",
    "        self.model = makeDNN(layers, nodes, activation)\n",
    "\n",
    "    def setFitness(self, testX, testY):\n",
    "        self._testLoss, self._testAccuracy = self.model.evaluate(testX, testY)\n",
    "\n",
    "    def getAccuracy(self):\n",
    "        return self._testAccuracy\n",
    "\n",
    "    def getLoss(self):\n",
    "        return self._testLoss\n",
    "\n",
    "    def train(self, trainX, trainY, epoch):\n",
    "        self.model.fit(trainX, trainY, epochs = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOVHtZkY7jHM"
   },
   "outputs": [],
   "source": [
    "class NeuroEvolution:\n",
    "    \n",
    "    population = []\n",
    "    newPopulation = []\n",
    "    populationSize = 0\n",
    "    maxLayers = 0\n",
    "    maxNodes = 0\n",
    "    maxIterations = 0\n",
    "    threshold = 0\n",
    "    activations = ['relu', 'sigmoid', 'tanh']\n",
    "    trend = []\n",
    "\n",
    "    def __init__(self, populationSize = 10, maxLayers = 7, maxNodes = 16, maxIterations = 5, threshold = 1):\n",
    "        self.populationSize = populationSize\n",
    "        self.maxLayers = maxLayers\n",
    "        self.maxNodes = maxNodes\n",
    "        self.maxIterations = maxIterations\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def initialize(self): # Generate random population\n",
    "        for i in range(self.populationSize):\n",
    "            self.newPopulation.append(NeuralNet(random.randint(1, self.maxLayers), random.randint(1, self.maxNodes), self.activations[random.randint(0, len(self.activations) - 1)]))\n",
    "\n",
    "    # Mutation\n",
    "    def mutate(self, nn):\n",
    "        chance = random.randint(1, 1000)\n",
    "        if(chance > 990):\n",
    "            nn.layers = random.randint(1, self.maxLayers)\n",
    "        chance = random.randint(1, 1000)\n",
    "        if(chance > 990):\n",
    "            nn.nodes = random.randint(1, self.maxNodes)\n",
    "        chance = random.randint(1, 1000)\n",
    "        if(chance > 990):\n",
    "            nn.activation = self.activations[random.randint(0, len(self.activations) - 1)]\n",
    "        return nn\n",
    "\n",
    "    # Crossover\n",
    "    def crossover(self, index1, index2):\n",
    "        randLayers = index1 if random.randint(0, 2) == 0 else index2\n",
    "        randNodes = index1 if random.randint(0, 2) == 0 else index2\n",
    "        randActivation = index1 if random.randint(0, 2) == 0 else index2\n",
    "        return NeuralNet(self.population[randLayers].layers, self.population[randNodes].nodes, self.population[randActivation].activation)\n",
    "\n",
    "\n",
    "    def trainAll(self, trainX, trainY, epoch):\n",
    "        for nn in self.newPopulation:\n",
    "            nn.train(trainX, trainY, epoch)\n",
    "\n",
    "    def setAllFitness(self, testX, testY):\n",
    "        for nn in self.newPopulation:\n",
    "            nn.setFitness(testX, testY)\n",
    "\n",
    "    # Print intermediate best result for an iteration\n",
    "    def printStatus(self, i):\n",
    "        print(\"Iteration \" + str(i))\n",
    "        print(\"\\tBest Accuracy = \" + str(self.population[0].getAccuracy()))\n",
    "        print(\"\\tBest Loss = \" + str(self.population[0].getLoss()))\n",
    "        for individual in self.population:\n",
    "            print(individual.getAccuracy())\n",
    "        self.trend.append(self.population[0].getAccuracy())\n",
    "\n",
    "    # Print final best result\n",
    "    def printBestResult(self):\n",
    "        print(\"Total number of iterations = \" + str(self.maxIterations))\n",
    "        print(\"Best Accuracy = \" + str(self.population[0].getAccuracy()))\n",
    "        print(\"Best Loss = \" + str(self.population[0].getLoss()))\n",
    "        print(\"Number of Layers = \" + str(self.population[0].layers))\n",
    "        print(\"Number of Nodes = \" + str(self.population[0].nodes))\n",
    "        print(\"Activation Function = \" + str(self.population[0].activation))\n",
    "        for ind in self.trend:\n",
    "            print(ind)\n",
    "\n",
    "    def run(self, trainX, trainY, testX, testY, epoch):\n",
    "        self.initialize() # Population initialization\n",
    "        tempStart = start\n",
    "        for i in range(self.maxIterations):\n",
    "            self.trainAll(trainX, trainY, epoch)\n",
    "            self.setAllFitness(testX, testY)\n",
    "            self.newPopulation = sorted(self.newPopulation, key = lambda net: net.getAccuracy(), reverse = True)\n",
    "            self.population = self.newPopulation[:self.populationSize]\n",
    "            self.newPopulation = []\n",
    "            self.printStatus(i)\n",
    "            if self.population[0].getAccuracy() >= self.threshold:\n",
    "                break\n",
    "            for j in range(int(self.populationSize/2)):\n",
    "                parent1 = 0\n",
    "                parent2 = 0\n",
    "                while parent1 == parent2:\n",
    "                    parent1 = random.randint(0, int(self.populationSize/2))\n",
    "                    parent2 = random.randint(0, int(self.populationSize/2))\n",
    "                self.newPopulation.append(self.crossover(parent1, parent2))\n",
    "            self.newPopulation += self.population[:int(self.populationSize/2)]\n",
    "            for nn in self.newPopulation:\n",
    "                nn = self.mutate(nn) # Mutation\n",
    "        self.printBestResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-6OXfBZpDLb9"
   },
   "outputs": [],
   "source": [
    "column_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "       'dst_host_srv_rerror_rate', 'class','difficulty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7DecNmi0Lztb"
   },
   "outputs": [],
   "source": [
    "class_dict = {'DOS':0, 'R2L':1, 'PROBE':2, 'U2R':3, 'NORMAL':4}  # custom labels hard coded\n",
    "\n",
    "# Reaing and Preprocessing\n",
    "def read():\n",
    "    train = pd.read_csv(r'../../Datasets/NSL_KDD/KDDTrain+.txt', sep=',',header = None, names = column_names) \n",
    "    train.drop(['difficulty'],axis=1,inplace=True)\n",
    "    change_label(train)\n",
    "    train_x = train[train.columns[:-1]]\n",
    "    normalization(train_x)\n",
    "    train_x = one_hot(train_x)\n",
    "    train_y = train[train.columns[-1]]\n",
    "    test = pd.read_csv(r'../../Datasets/NSL_KDD/KDDTest+.txt', sep=',',header = None, names = column_names)\n",
    "    test.drop(['difficulty'],axis=1,inplace=True)\n",
    "    change_label(test)\n",
    "    test_x = test[test.columns[:-1]]\n",
    "    normalization(test_x)\n",
    "    test_x = one_hot(test_x)\n",
    "    test_y = test[test.columns[-1]]\n",
    "    total_columns = list(set(train_x).union(set(test_x)))\n",
    "    total_columns.sort() \n",
    "    for j in set(total_columns)-set(train_x):\n",
    "        train_x[j] = 0.0\n",
    "    for j in set(total_columns)-set(test_x):\n",
    "        test_x[j] = 0.0\n",
    "    train_x = train_x[total_columns]\n",
    "    test_x = test_x[total_columns]\n",
    "    return train_x,train_y,test_x,test_y\n",
    "\n",
    "def change_label(df): # 5-classes including normal\n",
    "    df['class'].replace(['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm',\n",
    "                         'worm'],'DOS',inplace=True)\n",
    "    df['class'].replace(['ftp_write','guess_passwd','httptunnel','imap','multihop','named','phf','sendmail',\n",
    "       'snmpgetattack','snmpguess','spy','warezclient','warezmaster','xlock','xsnoop'],'R2L',inplace=True)\n",
    "    df['class'].replace(['ipsweep','mscan','nmap','portsweep','saint','satan'],'PROBE',inplace=True)\n",
    "    df['class'].replace(['buffer_overflow','loadmodule','perl','ps','rootkit','sqlattack','xterm'],'U2R',inplace=True)\n",
    "    df['class'].replace(['normal'],'NORMAL',inplace=True)\n",
    "    df['class'] = [class_dict[i] for i in df['class']]\n",
    "    \n",
    "def one_hot(df): # 3 categorical variables\n",
    "    category_columns = ['protocol_type','service','flag']\n",
    "    categorical = df[category_columns]\n",
    "    categorical = pd.get_dummies(categorical,columns = category_columns)\n",
    "    df = pd.concat([df, categorical], axis=1, join='inner')\n",
    "    df = df[list(set(df.columns) - set(category_columns))]\n",
    "    return df\n",
    "    \n",
    "def normalization(df): #Normalization \n",
    "    std_scaler = StandardScaler()\n",
    "    numeric_col = df.select_dtypes(include='float').columns\n",
    "    df[numeric_col] = StandardScaler().fit_transform(df[numeric_col])\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 310
    },
    "id": "C4HQ1eqnManL",
    "outputId": "4e8d20ae-4a33-45fd-8e23-1406d28b5b12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y,test_x,test_y = read()\n",
    "train_x,train_y,test_x,test_y = train_x.to_numpy(),train_y.to_numpy(),test_x.to_numpy(),test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBcnBoaCVceh"
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxiEmfnjV6Aq"
   },
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=10,n_jobs=-1)\n",
    "train_x, train_y = smt.fit_resample(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xP36rYPv7vx6",
    "outputId": "ce020497-02e9-440b-b7d0-5f0758c8ef56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.3219 - sparse_categorical_accuracy: 0.9035\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.3217 - sparse_categorical_accuracy: 0.9000\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2867 - sparse_categorical_accuracy: 0.9158\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.3088 - sparse_categorical_accuracy: 0.9054\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 42s 4ms/step - loss: 0.3423 - sparse_categorical_accuracy: 0.8894\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 40s 4ms/step - loss: 0.2845 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.2307 - sparse_categorical_accuracy: 0.9292\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.1982 - sparse_categorical_accuracy: 0.9408\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.1999 - sparse_categorical_accuracy: 0.9398\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.1812 - sparse_categorical_accuracy: 0.9465\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 42s 4ms/step - loss: 0.5097 - sparse_categorical_accuracy: 0.7990\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 43s 4ms/step - loss: 0.4561 - sparse_categorical_accuracy: 0.8257\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 43s 4ms/step - loss: 0.4034 - sparse_categorical_accuracy: 0.8583\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 45s 4ms/step - loss: 0.3806 - sparse_categorical_accuracy: 0.8648\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 44s 4ms/step - loss: 0.3619 - sparse_categorical_accuracy: 0.8729\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 31s 3ms/step - loss: 0.4885 - sparse_categorical_accuracy: 0.8377\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 31s 3ms/step - loss: 0.4280 - sparse_categorical_accuracy: 0.8686\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 31s 3ms/step - loss: 0.4079 - sparse_categorical_accuracy: 0.8780\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 32s 3ms/step - loss: 0.4013 - sparse_categorical_accuracy: 0.8806\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 31s 3ms/step - loss: 0.3894 - sparse_categorical_accuracy: 0.8878\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 40s 4ms/step - loss: 0.3381 - sparse_categorical_accuracy: 0.8902\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.2499 - sparse_categorical_accuracy: 0.9243\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 35s 3ms/step - loss: 0.2077 - sparse_categorical_accuracy: 0.9369\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.1867 - sparse_categorical_accuracy: 0.9453\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 34s 3ms/step - loss: 0.2015 - sparse_categorical_accuracy: 0.9381\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2558 - sparse_categorical_accuracy: 0.9231\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 40s 4ms/step - loss: 0.2364 - sparse_categorical_accuracy: 0.9307\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 40s 4ms/step - loss: 0.2164 - sparse_categorical_accuracy: 0.9384\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2050 - sparse_categorical_accuracy: 0.9432\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.1887 - sparse_categorical_accuracy: 0.9485\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.7958 - sparse_categorical_accuracy: 0.6203\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 40s 4ms/step - loss: 0.8565 - sparse_categorical_accuracy: 0.5834\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 43s 4ms/step - loss: 0.6180 - sparse_categorical_accuracy: 0.7247\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 48s 5ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.7260\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 48s 5ms/step - loss: 0.5804 - sparse_categorical_accuracy: 0.7350\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.3187 - sparse_categorical_accuracy: 0.8909\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 37s 3ms/step - loss: 0.2700 - sparse_categorical_accuracy: 0.9133\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 37s 3ms/step - loss: 0.2267 - sparse_categorical_accuracy: 0.9278\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.2074 - sparse_categorical_accuracy: 0.9284\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.1979 - sparse_categorical_accuracy: 0.9323\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.2602 - sparse_categorical_accuracy: 0.9174\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.2293 - sparse_categorical_accuracy: 0.9279\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 34s 3ms/step - loss: 0.2455 - sparse_categorical_accuracy: 0.9241\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 34s 3ms/step - loss: 0.2525 - sparse_categorical_accuracy: 0.9240\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 35s 3ms/step - loss: 0.2449 - sparse_categorical_accuracy: 0.9267\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 33s 3ms/step - loss: 0.5267 - sparse_categorical_accuracy: 0.8195\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 33s 3ms/step - loss: 0.4638 - sparse_categorical_accuracy: 0.8397\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 34s 3ms/step - loss: 0.4671 - sparse_categorical_accuracy: 0.8397\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 35s 3ms/step - loss: 0.4238 - sparse_categorical_accuracy: 0.8603\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 33s 3ms/step - loss: 0.3646 - sparse_categorical_accuracy: 0.9034\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 47s 4ms/step - loss: 0.2851 - sparse_categorical_accuracy: 0.9186\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 48s 5ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9215\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 47s 4ms/step - loss: 0.2411 - sparse_categorical_accuracy: 0.9308\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 46s 4ms/step - loss: 0.2149 - sparse_categorical_accuracy: 0.9384\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 49s 5ms/step - loss: 0.2074 - sparse_categorical_accuracy: 0.9427\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 1.2739 - sparse_categorical_accuracy: 0.4072\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 1.1593 - sparse_categorical_accuracy: 0.4633\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 1.1557 - sparse_categorical_accuracy: 0.4684\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 37s 3ms/step - loss: 1.0303 - sparse_categorical_accuracy: 0.5429\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.9937 - sparse_categorical_accuracy: 0.5674\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.5667 - sparse_categorical_accuracy: 0.8277\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.5666 - sparse_categorical_accuracy: 0.8124\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.4796 - sparse_categorical_accuracy: 0.8600\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.4831 - sparse_categorical_accuracy: 0.8567\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.5331 - sparse_categorical_accuracy: 0.8226\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.3897 - sparse_categorical_accuracy: 0.8449\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.3223 - sparse_categorical_accuracy: 0.8938\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.3094 - sparse_categorical_accuracy: 0.9018\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.2967 - sparse_categorical_accuracy: 0.9092\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9223\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.2823 - sparse_categorical_accuracy: 0.9079\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.2598 - sparse_categorical_accuracy: 0.9113\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.2341 - sparse_categorical_accuracy: 0.9229\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.2270 - sparse_categorical_accuracy: 0.9268\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 39s 4ms/step - loss: 0.2204 - sparse_categorical_accuracy: 0.9278\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 44s 4ms/step - loss: 0.5269 - sparse_categorical_accuracy: 0.7618\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.5045 - sparse_categorical_accuracy: 0.7650\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.5053 - sparse_categorical_accuracy: 0.7773\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.4933 - sparse_categorical_accuracy: 0.7802\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 42s 4ms/step - loss: 0.4863 - sparse_categorical_accuracy: 0.7879\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2730 - sparse_categorical_accuracy: 0.9127\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2442 - sparse_categorical_accuracy: 0.9227\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 42s 4ms/step - loss: 0.2103 - sparse_categorical_accuracy: 0.9352\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2244 - sparse_categorical_accuracy: 0.9265\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 41s 4ms/step - loss: 0.2193 - sparse_categorical_accuracy: 0.9262\n",
      "Epoch 1/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.2846 - sparse_categorical_accuracy: 0.9100\n",
      "Epoch 2/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9253\n",
      "Epoch 3/5\n",
      "10518/10518 [==============================] - 36s 3ms/step - loss: 0.2731 - sparse_categorical_accuracy: 0.9070\n",
      "Epoch 4/5\n",
      "10518/10518 [==============================] - 38s 4ms/step - loss: 0.2397 - sparse_categorical_accuracy: 0.9182\n",
      "Epoch 5/5\n",
      "10518/10518 [==============================] - 37s 4ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9204\n",
      "Epoch 1/5\n",
      " 9533/10518 [==========================>...] - ETA: 3s - loss: 0.4708 - sparse_categorical_accuracy: 0.8318"
     ]
    }
   ],
   "source": [
    "populationSize = 25\n",
    "maxLayers = 15\n",
    "maxNodes = 35\n",
    "maxIterations = 5\n",
    "threshold = 0.85\n",
    "\n",
    "Evolutor = NeuroEvolution(populationSize, maxLayers, maxNodes, maxIterations, threshold)\n",
    "Evolutor.run(train_x,train_y,test_x,test_y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HQua3OPKxw8"
   },
   "outputs": [],
   "source": [
    "# Result obtained from Neuroevolutionary algorithm\n",
    "model = makeDNN(2, 50, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpFe8ax_iZwf"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sqt70Go4Kxzy",
    "outputId": "c0d3f3d4-06bb-4c90-d750-bdd27dbf9ffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9471/9471 - 37s - loss: 0.3448 - accuracy: 0.9242 - val_loss: 2.1973 - val_accuracy: 0.1006 - 37s/epoch - 4ms/step\n",
      "Epoch 2/50\n",
      "9471/9471 - 35s - loss: 0.1678 - accuracy: 0.9573 - val_loss: 3.7711 - val_accuracy: 0.0000e+00 - 35s/epoch - 4ms/step\n",
      "Epoch 3/50\n",
      "9471/9471 - 36s - loss: 0.1485 - accuracy: 0.9618 - val_loss: 3.5293 - val_accuracy: 0.0231 - 36s/epoch - 4ms/step\n",
      "Epoch 4/50\n",
      "9471/9471 - 35s - loss: 0.1326 - accuracy: 0.9664 - val_loss: 2.8838 - val_accuracy: 0.0000e+00 - 35s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(train_x, train_y, validation_split=0.1, epochs=50,callbacks=[callback], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkMzxgj_Kx29",
    "outputId": "40e3f413-36da-4b06-ccd1-9f1a8c29f6d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91      7460\n",
      "           1       0.79      0.11      0.19      2885\n",
      "           2       0.73      0.86      0.79      2421\n",
      "           3       0.66      0.52      0.58        67\n",
      "           4       0.76      0.95      0.84      9711\n",
      "\n",
      "    accuracy                           0.81     22544\n",
      "   macro avg       0.64      0.56      0.55     22544\n",
      "weighted avg       0.81      0.81      0.77     22544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,np.argmax(model2.predict(test_x), axis=-1)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "neuroevolutionary_Nslkdd.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
