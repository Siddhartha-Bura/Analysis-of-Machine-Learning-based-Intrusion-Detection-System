{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc532c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING REQUIRED PACKAGES\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from random import randint, random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329f65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b23cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9e57b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7c1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bba4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baf818c",
   "metadata": {},
   "source": [
    "## Multi class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3cee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "       'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
    "       'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
    "       'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
    "       'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
    "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
    "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
    "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "       'dst_host_srv_rerror_rate', 'class','difficulty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a8b901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {'DOS':0, 'R2L':1, 'PROBE':2, 'U2R':3, 'NORMAL':4}  # custom labels hard coded\n",
    "\n",
    "# Reaing and Preprocessing\n",
    "def read():\n",
    "    train = pd.read_csv(r'../../Datasets/NSL_KDD/KDDTrain+.txt', sep=',',header = None, names = column_names) \n",
    "    train.drop(['difficulty'],axis=1,inplace=True)\n",
    "    change_label(train)\n",
    "    train_x = train[train.columns[:-1]]\n",
    "    normalization(train_x)\n",
    "    train_x = one_hot(train_x)\n",
    "    train_y = train[train.columns[-1]] \n",
    "    test = pd.read_csv(r'../../Datasets/NSL_KDD/KDDTest+.txt', sep=',',header = None, names = column_names)\n",
    "    test.drop(['difficulty'],axis=1,inplace=True)\n",
    "    change_label(test)\n",
    "    test_x = test[test.columns[:-1]]\n",
    "    normalization(test_x)\n",
    "    test_x = one_hot(test_x)\n",
    "    test_y = test[test.columns[-1]] \n",
    "    total_columns = list(set(train_x).union(set(test_x)))\n",
    "    total_columns.sort() \n",
    "    for j in set(total_columns)-set(train_x):\n",
    "        train_x[j] = 0.0\n",
    "    for j in set(total_columns)-set(test_x):\n",
    "        test_x[j] = 0.0\n",
    "    train_x = train_x[total_columns]\n",
    "    test_x = test_x[total_columns]\n",
    "    return train_x,train_y,test_x,test_y\n",
    "\n",
    "def change_label(df): # 5-classes including normal\n",
    "    df['class'].replace(['apache2','back','land','neptune','mailbomb','pod','processtable','smurf','teardrop','udpstorm',\n",
    "                         'worm'],'DOS',inplace=True)\n",
    "    df['class'].replace(['ftp_write','guess_passwd','httptunnel','imap','multihop','named','phf','sendmail',\n",
    "       'snmpgetattack','snmpguess','spy','warezclient','warezmaster','xlock','xsnoop'],'R2L',inplace=True)\n",
    "    df['class'].replace(['ipsweep','mscan','nmap','portsweep','saint','satan'],'PROBE',inplace=True)\n",
    "    df['class'].replace(['buffer_overflow','loadmodule','perl','ps','rootkit','sqlattack','xterm'],'U2R',inplace=True)\n",
    "    df['class'].replace(['normal'],'NORMAL',inplace=True)\n",
    "    df['class'] = [class_dict[i] for i in df['class']]\n",
    "    \n",
    "def one_hot(df): # 3 categorical variables\n",
    "    category_columns = ['protocol_type','service','flag']\n",
    "    categorical = df[category_columns]\n",
    "    categorical = pd.get_dummies(categorical,columns = category_columns)\n",
    "    df = pd.concat([df, categorical], axis=1, join='inner')\n",
    "    df = df[list(set(df.columns) - set(category_columns))]\n",
    "    return df\n",
    "    \n",
    "def normalization(df): #Normalization\n",
    "    std_scaler = StandardScaler()\n",
    "    numeric_col = df.select_dtypes(include='float').columns\n",
    "    df[numeric_col] = StandardScaler().fit_transform(df[numeric_col])\n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd37d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_finder(): # Initialized optimal features using correlations\n",
    "    train_x, train_y, test_x, test_y = read()\n",
    "    s = correlation(train_x,0.90)\n",
    "    ans = set()\n",
    "    for x in range(20):\n",
    "        temp_ans = set()\n",
    "        for i in s:\n",
    "            temp_ans.add(i[randint(0, 1)])\n",
    "        ans.add(frozenset(temp_ans))\n",
    "    df = train_x.copy()\n",
    "    df['class'] = train_y \n",
    "    ts = correlation_test(df,0.50)-{'class'}\n",
    "    lis_col = list(train_x.columns)\n",
    "    pakka = []\n",
    "    for i in ts:\n",
    "        pakka.append(lis_col.index(i))\n",
    "    popu = []\n",
    "    for i in ans:\n",
    "        ans = [0]*len(lis_col)\n",
    "        for j in pakka:\n",
    "            ans[j]=1\n",
    "        for j in i:\n",
    "            ans[lis_col.index(j)] = 1\n",
    "        popu.append(ans)\n",
    "    return popu\n",
    "\n",
    "def correlation(df, threshold):\n",
    "    col_corr = set()  # Set of all pairs of correlated columns as sets\n",
    "    corr_matrix = df.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if corr_matrix.iloc[i, j] > threshold: # we are interested in absolute coeff value\n",
    "                colname1 = corr_matrix.columns[i] \n",
    "                colname2 = corr_matrix.columns[j]\n",
    "                col_corr.add((colname1,colname2))\n",
    "    return col_corr\n",
    "\n",
    "def correlation_test(df, threshold):\n",
    "    col_corr = set()  # Set of all pairs of correlated columns as sets\n",
    "    corr_matrix = df.corr()\n",
    "    for i in corr_matrix.columns:\n",
    "        if corr_matrix[i]['class'] > threshold:\n",
    "            col_corr.add(i)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c5795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_features_data(individual, x): # selects features based on individual\n",
    "    col_names = x.columns\n",
    "    selected_columns = [col_names[i] for i in range(len(individual)) if(individual[i] == 1)] \n",
    "    selected_f = x[selected_columns].copy()\n",
    "    return selected_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c1bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(population_size, len_x,col): # Population Generation\n",
    "    ans = []\n",
    "    for i in range(population_size):\n",
    "        sf = [0] * len_x\n",
    "        for i in range(len(sf)):\n",
    "            sf[i] = randint(0, 1)\n",
    "        ans.append(sf)\n",
    "    popu = correlation_finder()\n",
    "    for i in range(len(popu)):\n",
    "        if i<population_size:\n",
    "            ans[i] = popu[i]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bee2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_y(class_prob): # Return predicted class labels\n",
    "    predict_y = []\n",
    "    for i in class_prob:\n",
    "        predict_y.append(i.argmax())    \n",
    "    return predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual, clf, data): # Fitness function evaluation\n",
    "    selected_train_x = get_selected_features_data(individual, data[0]) \n",
    "    selected_test_x = get_selected_features_data(individual, data[2])\n",
    "    clf = clf.fit(selected_train_x.to_numpy(), data[1].values.tolist()) \n",
    "    class_prob = clf.predict_proba(selected_test_x.to_numpy())\n",
    "    predict_y = predicted_y(class_prob)\n",
    "    fitness_ans = 1-cohen_kappa_score(data[3],predict_y) # taking 1- because we are minimizing cost\n",
    "    return fitness_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_miss_rate(test_y, predict_y): \n",
    "    miss = [0]*len(class_dict)\n",
    "    total = [0]*len(class_dict)\n",
    "    miss_percent = [0.0]*len(class_dict)\n",
    "    rev_class_dict = {v: k for k, v in class_dict.items()} # reverse class dictionary of hard coded labels\n",
    "    for i in range(len(test_y)):\n",
    "        index = class_dict[rev_class_dict[test_y[i]]]\n",
    "        total[index] += 1\n",
    "        if test_y[i] != predict_y[i]:\n",
    "            miss[index] += 1\n",
    "    for i in range(len(miss_percent)):\n",
    "        miss_percent[i] = (100.00 * miss[i]) / total[i]\n",
    "        if miss_percent[i]<=1: # to not collapse fitness to 0 unnecessarily because of one good accuracy class\n",
    "            miss_percent[i] = 1\n",
    "    return miss_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_fitness(population, clf, data): # Calculates average fitness for a population\n",
    "    total_fitness = 0\n",
    "    fitness_individual = []\n",
    "    for i in population:\n",
    "        total_fitness += fitness(i, clf, data)\n",
    "        fitness_individual.append([fitness(i, clf, data),i])\n",
    "    fitness_individual.sort(key=lambda x:x[0])\n",
    "    return total_fitness / len(population),fitness_individual[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7783fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutation, Crossover , Selection\n",
    "def evolve(pop, clf, data, retain_percentage = 0.50, random_select = 0.05, mutate_prob = 0.01):\n",
    "    f_values = [(fitness(i, clf, data), i) for i in pop] #i = [0,1,1,0,...]\n",
    "    individuals = [i[1] for i in sorted(f_values)]\n",
    "    retain_length = int(len(pop) * retain_percentage)\n",
    "    parents = individuals[:retain_length]\n",
    "    \n",
    "    # randomly add other individuals to increase diversity\n",
    "    for i in individuals[retain_length:]:\n",
    "        if random_select > random():\n",
    "            parents.append(i)\n",
    "            \n",
    "    # mutate\n",
    "    for i in parents:\n",
    "        if mutate_prob > random():\n",
    "            index_to_mutate = randint(0, len(i) - 1)\n",
    "            i[index_to_mutate] = randint(0, 1)\n",
    "    \n",
    "    # crossover\n",
    "    no_of_parents = len(parents)\n",
    "    remaining_no_of_ind = len(pop) - no_of_parents\n",
    "    children = []\n",
    "    \n",
    "    while len(children) < remaining_no_of_ind:\n",
    "        male_index = randint(0, no_of_parents - 1)\n",
    "        female_index = randint(0, no_of_parents - 1)\n",
    "        \n",
    "        if male_index != female_index:\n",
    "            male = parents[male_index]\n",
    "            female = parents[female_index]\n",
    "            half = int(len(male) / 2)\n",
    "            child = male[:half] + female[half:]\n",
    "            children.append(child)\n",
    "    \n",
    "    parents.extend(children)\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f10dba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genetic Algorithm\n",
    "def ga():\n",
    "    train_x, train_y, test_x, test_y = read()\n",
    "    smote = SMOTE()\n",
    "    train_x, train_y = smote.fit_resample(train_x, train_y)\n",
    "    data = [train_x, train_y, test_x, test_y]\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    population_size = 10\n",
    "    pop = generate_population(population_size, len(train_x[:1].values[0].tolist()),list(train_x.columns))  # Random\n",
    "    fitness_list = []\n",
    "    for i in range(250): # give sufficient iterations\n",
    "        pop = evolve(pop, clf, data)\n",
    "        population_fitness,best_individual = average_fitness(pop, clf, data) # average fitness for all individuals in a population\n",
    "        fitness_list.append(population_fitness)\n",
    "        print(i,\"_pop_fitness : \",population_fitness)\n",
    "        print(best_individual)\n",
    "        if population_fitness < 0.1:\n",
    "            break\n",
    "    print (fitness_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "733ce2ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "0 _pop_fitness :  0.6826256777074563\n",
      "[0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "1 _pop_fitness :  0.6674907857569753\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "2 _pop_fitness :  0.6608894184444416\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "3 _pop_fitness :  0.6584841411125815\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "4 _pop_fitness :  0.658664122836799\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "5 _pop_fitness :  0.6549326853561518\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "6 _pop_fitness :  0.6555100062169369\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "7 _pop_fitness :  0.6491821329840006\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6837/2471064534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mga\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6837/1522227302.py\u001b[0m in \u001b[0;36mga\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpopulation_fitness\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_individual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# average fitness for all individuals in a population\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mfitness_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation_fitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_pop_fitness : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpopulation_fitness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6837/3498846764.py\u001b[0m in \u001b[0;36maverage_fitness\u001b[0;34m(population, clf, data)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mtotal_fitness\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mfitness_individual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mfitness_individual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_fitness\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfitness_individual\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6837/3498846764.py\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(individual, clf, data)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mselected_test_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_selected_features_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_train_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mclass_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_test_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mpredict_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kmohan/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kmohan/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ga()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975232bd",
   "metadata": {},
   "source": [
    "### Classifiers with all features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a24c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def util(train_x, train_y, test_x, test_y,clf):\n",
    "    clf = clf.fit(train_x.to_numpy(), train_y.values.tolist())\n",
    "    class_prob = clf.predict_proba(test_x.to_numpy())\n",
    "    predict_y = predicted_y(class_prob)\n",
    "    miss_percent = calculate_class_miss_rate(test_y, predict_y)\n",
    "    count = 1\n",
    "    for i in miss_percent:\n",
    "        print(count,\"class no accuracy : \",100-i)\n",
    "        count+=1\n",
    "    fitness_ans = 1-cohen_kappa_score(test_y,predict_y) # taking 1- because we are minimizing cost\n",
    "    target_names = ['DOS', 'R2L', 'PROBE', 'U2R', 'NORMAL']\n",
    "    print(fitness_ans)\n",
    "    print(classification_report(test_y,predict_y,target_names=target_names))\n",
    "\n",
    "# Results on classifires on all features selcted\n",
    "def traditional():\n",
    "    train_x, train_y, test_x, test_y = read()\n",
    "    smote = SMOTE()\n",
    "    train_x, train_y = smote.fit_resample(train_x, train_y)\n",
    "    print(\"DecisionTreeClassifier : \")\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    util(train_x, train_y, test_x, test_y,clf)\n",
    "    print(\"KNeighborsClassifier : \")\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    util(train_x, train_y, test_x, test_y,clf)\n",
    "    print(\"RandomForestClassifier : \")\n",
    "    clf = RandomForestClassifier()\n",
    "    util(train_x, train_y, test_x, test_y,clf)\n",
    "    print(\"MLPClassifier : \")\n",
    "    clf = MLPClassifier(hidden_layer_sizes = [100]*5)\n",
    "    util(train_x, train_y, test_x, test_y,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edb01e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "DecisionTreeClassifier : \n",
      "1 class no accuracy :  60.83109919571046\n",
      "2 class no accuracy :  7.5909878682842304\n",
      "3 class no accuracy :  46.551011978521274\n",
      "4 class no accuracy :  2.985074626865668\n",
      "5 class no accuracy :  96.11780455153949\n",
      "0.5098458972846518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.88      0.61      0.72      7460\n",
      "         R2L       0.41      0.08      0.13      2885\n",
      "       PROBE       0.43      0.47      0.45      2421\n",
      "         U2R       0.06      0.03      0.04        67\n",
      "      NORMAL       0.66      0.96      0.78      9711\n",
      "\n",
      "    accuracy                           0.68     22544\n",
      "   macro avg       0.49      0.43      0.42     22544\n",
      "weighted avg       0.67      0.68      0.64     22544\n",
      "\n",
      "KNeighborsClassifier : \n",
      "1 class no accuracy :  75.36193029490616\n",
      "2 class no accuracy :  21.90641247833622\n",
      "3 class no accuracy :  64.97315159025196\n",
      "4 class no accuracy :  44.776119402985074\n",
      "5 class no accuracy :  96.21048295747092\n",
      "0.37166746353088675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.94      0.75      0.83      7460\n",
      "         R2L       0.91      0.22      0.35      2885\n",
      "       PROBE       0.74      0.65      0.69      2421\n",
      "         U2R       0.29      0.45      0.36        67\n",
      "      NORMAL       0.69      0.96      0.80      9711\n",
      "\n",
      "    accuracy                           0.76     22544\n",
      "   macro avg       0.71      0.61      0.61     22544\n",
      "weighted avg       0.80      0.76      0.74     22544\n",
      "\n",
      "RandomForestClassifier : \n",
      "1 class no accuracy :  60.107238605898125\n",
      "2 class no accuracy :  9.012131715771233\n",
      "3 class no accuracy :  80.2147872779843\n",
      "4 class no accuracy :  0.0\n",
      "5 class no accuracy :  97.14756461744413\n",
      "0.4447942986488074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.95      0.60      0.74      7460\n",
      "         R2L       0.97      0.09      0.16      2885\n",
      "       PROBE       0.59      0.80      0.68      2421\n",
      "         U2R       0.00      0.00      0.00        67\n",
      "      NORMAL       0.66      0.97      0.79      9711\n",
      "\n",
      "    accuracy                           0.72     22544\n",
      "   macro avg       0.63      0.49      0.47     22544\n",
      "weighted avg       0.79      0.72      0.68     22544\n",
      "\n",
      "MLPClassifier : \n",
      "1 class no accuracy :  74.6514745308311\n",
      "2 class no accuracy :  14.350086655112648\n",
      "3 class no accuracy :  61.29698471705907\n",
      "4 class no accuracy :  80.59701492537313\n",
      "5 class no accuracy :  87.26186798475955\n",
      "0.4320768722095367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.95      0.75      0.83      7460\n",
      "         R2L       0.93      0.14      0.25      2885\n",
      "       PROBE       0.79      0.61      0.69      2421\n",
      "         U2R       0.02      0.81      0.05        67\n",
      "      NORMAL       0.71      0.87      0.78      9711\n",
      "\n",
      "    accuracy                           0.71     22544\n",
      "   macro avg       0.68      0.64      0.52     22544\n",
      "weighted avg       0.82      0.71      0.72     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traditional()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac154f",
   "metadata": {},
   "source": [
    "### Applying results of genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12417a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the fittest individual obtained\n",
    "def fittest(individual):\n",
    "    train_x, train_y, test_x, test_y = read()\n",
    "    smote = SMOTE()                            # Over sampling using smote\n",
    "    train_x, train_y = smote.fit_resample(train_x, train_y)\n",
    "    train_x = get_selected_features_data(individual, train_x)\n",
    "    test_x = get_selected_features_data(individual,test_x)\n",
    "    print(\"DecisionTreeClassifier : \")\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    util(train_x, train_y, test_x, test_y,clf)\n",
    "    print(\"KNeighborsClassifier : \")\n",
    "    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "    util(train_x, train_y, test_x, test_y,clf)\n",
    "    print(\"RandomForestClassifier : \")\n",
    "    clf = RandomForestClassifier()\n",
    "    util(train_x, train_y, test_x, test_y,clf)\n",
    "    print(\"MLPClassifier : \")\n",
    "    clf = MLPClassifier(hidden_layer_sizes = [100]*5)\n",
    "    util(train_x, train_y, test_x, test_y,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97eb1c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/kmohan/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "DecisionTreeClassifier : \n",
      "1 class no accuracy :  85.33512064343164\n",
      "2 class no accuracy :  15.875216637781634\n",
      "3 class no accuracy :  91.86286658405618\n",
      "4 class no accuracy :  17.910447761194035\n",
      "5 class no accuracy :  95.9221501390176\n",
      "0.28261348824954824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.98      0.85      0.91      7460\n",
      "         R2L       0.90      0.16      0.27      2885\n",
      "       PROBE       0.77      0.92      0.84      2421\n",
      "         U2R       0.03      0.18      0.05        67\n",
      "      NORMAL       0.76      0.96      0.85      9711\n",
      "\n",
      "    accuracy                           0.82     22544\n",
      "   macro avg       0.69      0.61      0.58     22544\n",
      "weighted avg       0.85      0.82      0.79     22544\n",
      "\n",
      "KNeighborsClassifier : \n",
      "1 class no accuracy :  79.6916890080429\n",
      "2 class no accuracy :  12.097053726169847\n",
      "3 class no accuracy :  87.81495249896737\n",
      "4 class no accuracy :  35.82089552238806\n",
      "5 class no accuracy :  90.20698177324684\n",
      "0.3584108887446472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.95      0.80      0.87      7460\n",
      "         R2L       0.82      0.12      0.21      2885\n",
      "       PROBE       0.69      0.88      0.77      2421\n",
      "         U2R       0.03      0.36      0.06        67\n",
      "      NORMAL       0.73      0.90      0.81      9711\n",
      "\n",
      "    accuracy                           0.76     22544\n",
      "   macro avg       0.64      0.61      0.54     22544\n",
      "weighted avg       0.81      0.76      0.74     22544\n",
      "\n",
      "RandomForestClassifier : \n",
      "1 class no accuracy :  85.02680965147454\n",
      "2 class no accuracy :  15.944540727902947\n",
      "3 class no accuracy :  93.14332920280876\n",
      "4 class no accuracy :  28.358208955223887\n",
      "5 class no accuracy :  96.32375656472043\n",
      "0.2814856333133131\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.98      0.85      0.91      7460\n",
      "         R2L       0.91      0.16      0.27      2885\n",
      "       PROBE       0.77      0.93      0.84      2421\n",
      "         U2R       0.23      0.28      0.25        67\n",
      "      NORMAL       0.74      0.96      0.84      9711\n",
      "\n",
      "    accuracy                           0.82     22544\n",
      "   macro avg       0.73      0.64      0.62     22544\n",
      "weighted avg       0.85      0.82      0.79     22544\n",
      "\n",
      "MLPClassifier : \n",
      "1 class no accuracy :  77.88203753351206\n",
      "2 class no accuracy :  6.932409012131714\n",
      "3 class no accuracy :  90.12804626187526\n",
      "4 class no accuracy :  55.223880597014926\n",
      "5 class no accuracy :  89.23900731129646\n",
      "0.3687219026142565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         DOS       0.96      0.78      0.86      7460\n",
      "         R2L       0.61      0.07      0.12      2885\n",
      "       PROBE       0.66      0.90      0.76      2421\n",
      "         U2R       0.02      0.55      0.04        67\n",
      "      NORMAL       0.77      0.89      0.83      9711\n",
      "\n",
      "    accuracy                           0.75     22544\n",
      "   macro avg       0.60      0.64      0.52     22544\n",
      "weighted avg       0.80      0.75      0.74     22544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Best result obtained from genetic algorithm\n",
    "fittest([1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
